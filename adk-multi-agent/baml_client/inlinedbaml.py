###############################################################################
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml-py
#
###############################################################################

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code.
#
# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

file_map = {
    
    "agent_calendar.baml": "// Defining a data model.\nclass CalendarActionToolCall {\n  action \"tool_call\" @description(\"Call a tool to get the calendar events.\")\n  tool CalendarListEventsTool | CalendarScheduleEventTool\n}\n\nclass CalendarActionEnd {\n  action \"end\" @description(\"End and exit the conversation with a summary.\")\n  answer string @description(\"Answer to the user's request in a polite and humble manner.\")\n}\n\nclass CalendarActionInputRequired {\n  action \"input_required\" @description(\"User's input is required to continue.\")\n  prompt string @description(\"Prompt to the user to provide the missing information.\")\n}\n\nclass CalendarListEventsTool {\n  tool \"list_events\" @description(\"Get the calendar events.\")\n  args CalendarListEventsToolArgs\n}\n\nclass CalendarScheduleEventTool {\n  tool \"schedule_event\" @description(\"Schedule a new event.\")\n  args CalendarScheduleEventToolArgs\n}\n\nclass CalendarListEventsToolArgs {\n  start_time string @description(\"The start of the time frame (ISO format: YYYY-MM-DDTHH:MM:SS).\")\n  end_time string @description(\"The end of the time frame (ISO format: YYYY-MM-DDTHH:MM:SS).\")\n}\n\nclass CalendarScheduleEventToolArgs {\n  title string @description(\"The title of the event.\")\n  time_start string @description(\"The start of the event (ISO format: YYYY-MM-DDTHH:MM:SS).\")\n  time_end string @description(\"The end of the event (ISO format: YYYY-MM-DDTHH:MM:SS).\")\n}\n\nfunction CalendarNextAction(context: string, additional_instructions: string, date_today: string) -> CalendarActionToolCall | CalendarActionEnd | CalendarActionInputRequired {\n  // Specify a client as provider/model-name\n  // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\n  client Gemini_2_5_Flash\n  prompt #\"\n    Identify the next action to take based on the provided context\n\n    # Instructions\n    - We are not allowed to schedule events in the past.\n    - Once the user's request is complete, you should end the conversation with an answer. The answer should be in a human readable markdown format.\n    - If you do not have enough information to complete the user's request, you should ask the user for the missing information. Be clear about the missing information.\n    \n    # Effort Mapping\n    - very-high: 4 hours or more\n    - high: 2 hours or more\n    - medium: 1 hour or more\n    - low: 30 minutes or more\n    - very-low: less than 30 minutes\n    \n    # Additional instructions\n    {{ additional_instructions }}\n\n    # Today's date\n    {{ date_today }}\n    \n    # Context\n    {{ context }}\n\n    # Output format\n    {{ ctx.output_format }}\n    \n    Think step by step before outputting the result in JSON format.\n  \"#\n}\n",
    "agent_custom.baml": "class AssistantActionAgent {\n  action \"transfer_to_agent\" @description(\"Transfer to the agent.\")\n  agent AgentName\n  tasks string[]\n  context string @description(\n    #\"\n      Exhaustive context of the conversation to make sure the agent has all the information to complete the task.\n      This field should be a multi-line string. Example:\n      {\n        ...,\n        \"context\": \"\"\"\n          [Descriptive context of the conversation]\n        \"\"\"\n      }\n    \"#)\n}\n\nclass AssistantActionInputRequired {\n  action \"input_required\" @description(\"None of the agents have enough information to complete the user's request. User's input is required to continue.\")\n  prompt string @description(\n    #\"\n      Prompt to ask the user for the missing information. Make sure to use human readable markdown format.\n      This field should be a multi-line string. Example:\n      {\n        ...,\n        \"prompt\": \"\"\"\n          [Prompt to ask the user for the missing information]\n        \"\"\"\n      }\n    \"#\n  )\n}\n\nclass AssistantActionEnd {\n  action \"end\" @description(\"End the conversation.\")\n  answer string @description(\"Answer to the user's request in a polite and humble manner.\")\n}\n\nenum AgentName {\n  @@dynamic\n}\n\nclass CalendarAgent {\n  agent_name AgentName\n  query string\n}\n\nclass ProjectAgent {\n  agent_name \"project_manager\" @description(\"Agent to manage and retrieve information about projects and their tasks.\")\n  query string\n}\n\nfunction AssistantNextAction(context: string) -> AssistantActionAgent | AssistantActionEnd | AssistantActionInputRequired {\n  // Specify a client as provider/model-name\n  // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\n  client Gemini_2_5_Flash\n  prompt #\"\n    Identify the next best action to take based on the provided context\n\n    # Instructions\n    - Delegate the tasks to the various agents. Use the agent description to determine the best agent to delegate the task to.\n    - Agents can do a lot more than their sample queries. Feel free to delegate complex composite tasks to the agents.\n    - When dealing with missing information, try breaking the tasks down into smaller tasks. Group the tasks to the same agent if possible.\n    - Once the user's request is complete, you should end the conversation with an answer. The answer should be in a human readable markdown format.\n    - Use \"input_required\" action only if:\n        1. You don't know which agent to delegate the task to.\n        2. The agent requests more information.\n        3. Never ask the user questions preemptively. Let the agents ask the questions.\n\n    # Context\n    {{ context }}\n\n    # Output format\n    {{ ctx.output_format }}\n    \n    Output step by step reasoning before outputting the result in JSON format.\n  \"#\n}",
    "agent_helpers.baml": "class AgentActionEnd {\n  action \"end\" @description(\"End and exit the conversation with a result.\")\n  result string @description(#\"\n    Result of the user's request in a polite and humble manner.\n    Always provide the output in human readable markdown format. Include all the information in the output.\n    This should be a multi-line string. Example:\n    {\n      \"action\": \"end\",\n      \"result\": \"\"\"\n        [Result goes here]\n      \"\"\"\n    }\n  \"#)\n}\n\nclass AgentActionInputRequired {\n  action \"input_required\" @description(\"User's input is required to continue.\")\n  prompt string @description(\"Prompt to the user to provide the missing information.\")\n}",
    "agent_project_manager.baml": "// Defining a data model.\nclass ProjectManagerActionToolCall {\n  action \"tool_call\" @description(\"Call a tool to get the calendar events.\")\n  tool ProjectManagerListProjectsTool | ProjectManagerGetProjectTasksTool\n}\n\nclass ProjectManagerListProjectsTool {\n  name \"list_all_projects\" @description(\"Get the list of projects.\")\n}\n\nclass ProjectManagerGetProjectTasksTool {\n  name \"get_project_tasks\" @description(\"Get the list of tasks for a given project.\")\n  args ProjectManagerGetProjectTasksToolArgs\n}\n\nclass ProjectManagerGetProjectTasksToolArgs {\n  project_id string @description(\"The id of the project to get the tasks for.\")\n}\n\nfunction ProjectManagerNextAction(context: string) -> ProjectManagerActionToolCall | AgentActionEnd | AgentActionInputRequired {\n  // Specify a client as provider/model-name\n  // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\n  client Gemini_2_5_Flash\n  prompt #\"\n    Identify the next action to take based on the provided context\n\n    # Instructions\n    - Break down the user's request into smaller steps if needed.\n    - Project ids are not human readable. You need to list all projects to get the project id.\n    - Once the user's request is complete, you should end the conversation with an answer. The answer should be in a human readable markdown format.\n    - If you do not have enough information to complete the user's request, you should ask the user for the missing information. Be clear about the missing information.\n    \n    # Context\n    {{ context }}\n\n    # Output format\n    {{ ctx.output_format }}\n    \n    Print step by step reasoningbefore outputting the result in JSON format.\n  \"#\n}\n\ntest pm_agent_GetProjectTasks {\n  functions [ProjectManagerNextAction]\n  args {\n    context #\"\n      List all tasks for project mewto\n    \"#\n  }\n}",
    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> Gemini_2_5_Flash {\n  provider google-ai\n  options {\n    model \"gemini-2.5-flash\"\n    api_key env.GOOGLE_API_KEY\n  }\n}\n",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.90.1\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
}

def get_baml_files():
    return file_map